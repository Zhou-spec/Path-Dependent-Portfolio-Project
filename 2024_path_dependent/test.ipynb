{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate one path for n assets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from simulation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleLSTMModel(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size=1):  # Output size is set to 1 by default\n",
    "        super(SimpleLSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        # LSTM layer expects input of shape (batch_size, seq_length, features)\n",
    "        # For a univariate sequence, features=1\n",
    "        self.lstm = nn.LSTM(1, hidden_size, batch_first=True)\n",
    "        # Fully connected layer to map the hidden state output to the desired output size\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add a batch dimension and feature dimension to x\n",
    "        # Reshaping x from (n,) to (1, n, 1) to fit LSTM input requirements\n",
    "        x = x.unsqueeze(0).unsqueeze(-1)  # Now x is of shape [1, seq_length, 1]\n",
    "        # Process x through the LSTM\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # Only use the output from the last time step\n",
    "        # This assumes you're interested in the final output for sequence processing\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        # Squeeze the output to remove 1-dimensions, aiming for a scalar output\n",
    "        return out.squeeze()\n",
    "\n",
    "# Initialize the model\n",
    "hidden_size = 10  # Number of LSTM units in the hidden layer\n",
    "\n",
    "model = SimpleLSTMModel(hidden_size)\n",
    "x = torch.randn(50)\n",
    "f = Functional(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = generate_asset_path(mu = np.array([0.1, 0.2]), sigma = np.array([[0.3, 0.4], [0.1, 0.2]]), T = 1, dt = 0.01)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4828312758041713"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a class of trading policy \n",
    "# the trading policy object\n",
    "\n",
    "naive_states = np.array([[0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5], [0.5, 0.6]])\n",
    "\n",
    "policy = Trading_Policy(f, naive_states)\n",
    "\n",
    "policy.entropy(path[0], mu = np.array([0.1, 0.2]), sigma = np.array([[0.3, 0.4], [0.1, 0.2]]), dt = 0.01, h = 0.02, gamma = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "holding_history, wealth_history = simulated_trading(policy, path, 1, np.array([0.1, 0.2]), np.array([[0.3, 0.4], [0.1, 0.2]]), 0.01, 0.1, 0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 38\u001b[0m\n\u001b[0;32m     36\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     37\u001b[0m wealth_hisotry \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(wealth_history, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 38\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mone_path_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_value_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwealth_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# move loss to GPU \u001b[39;00m\n\u001b[0;32m     40\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[1;32mIn[44], line 25\u001b[0m, in \u001b[0;36mone_path_loss\u001b[1;34m(new_value_net, policy, wealth_history, dt, h, gamma, mu, sigma)\u001b[0m\n\u001b[0;32m     23\u001b[0m     x_short \u001b[38;5;241m=\u001b[39m wealth_history[:i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     24\u001b[0m     value_derivative \u001b[38;5;241m=\u001b[39m (new_value_net(x) \u001b[38;5;241m-\u001b[39m new_value_net(x_short)) \u001b[38;5;241m/\u001b[39m dt\n\u001b[1;32m---> 25\u001b[0m     entropy \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     TD_error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (value_derivative \u001b[38;5;241m+\u001b[39m entropy) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m        \n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m TD_error \u001b[38;5;241m*\u001b[39m dt\n",
      "File \u001b[1;32mc:\\Users\\specf\\OneDrive\\Documents\\GitHub\\Path-Dependent-Portfolio-Project\\2024_path_dependent\\simulation.py:173\u001b[0m, in \u001b[0;36mTrading_Policy.entropy\u001b[1;34m(self, x, mu, sigma, dt, h, gamma)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mentropy\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mu, sigma, dt, h, gamma):\n\u001b[1;32m--> 173\u001b[0m     dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(dist \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(dist)) \u001b[38;5;241m*\u001b[39m gamma\n",
      "File \u001b[1;32mc:\\Users\\specf\\OneDrive\\Documents\\GitHub\\Path-Dependent-Portfolio-Project\\2024_path_dependent\\simulation.py:154\u001b[0m, in \u001b[0;36mTrading_Policy.distribution\u001b[1;34m(self, x, mu, sigma, dt, h, gamma)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstates)):\n\u001b[0;32m    153\u001b[0m     holdings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstates[i]\n\u001b[1;32m--> 154\u001b[0m     dist[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribution_numerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mholdings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# we have to softmax the dist, and normalize it\u001b[39;00m\n\u001b[0;32m    157\u001b[0m dist \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(dist) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mexp(dist))\n",
      "File \u001b[1;32mc:\\Users\\specf\\OneDrive\\Documents\\GitHub\\Path-Dependent-Portfolio-Project\\2024_path_dependent\\simulation.py:134\u001b[0m, in \u001b[0;36mTrading_Policy.distribution_numerator\u001b[1;34m(self, x, mu, sigma, holdings, dt, h, gamma)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdistribution_numerator\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mu, sigma, holdings, dt, h, gamma):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;66;03m# x is the sequence (path of the asset prices)\u001b[39;00m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;66;03m# mu is the expected return of the assets\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;66;03m# h is the increment for the partial_xx\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# gamma is the risk aversion coefficient\u001b[39;00m\n\u001b[0;32m    133\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor(x)\n\u001b[1;32m--> 134\u001b[0m     par_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_t\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m     par_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mpartial_x(x, h)\n\u001b[0;32m    136\u001b[0m     par_xx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mpartial_xx(x, h)\n",
      "File \u001b[1;32mc:\\Users\\specf\\OneDrive\\Documents\\GitHub\\Path-Dependent-Portfolio-Project\\2024_path_dependent\\simulation.py:58\u001b[0m, in \u001b[0;36mFunctional.partial_t\u001b[1;34m(self, x, dt)\u001b[0m\n\u001b[0;32m     56\u001b[0m new_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x, x[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)))\n\u001b[0;32m     57\u001b[0m new_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_network(new_x)\n\u001b[1;32m---> 58\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m partial_t \u001b[38;5;241m=\u001b[39m (new_output \u001b[38;5;241m-\u001b[39m output) \u001b[38;5;241m/\u001b[39m dt\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m partial_t\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[37], line 19\u001b[0m, in \u001b[0;36mSimpleLSTMModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Now x is of shape [1, seq_length, 1]\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Process x through the LSTM\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m lstm_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Only use the output from the last time step\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# This assumes you're interested in the final output for sequence processing\u001b[39;00m\n\u001b[0;32m     22\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(lstm_out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n",
      "File \u001b[1;32mc:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:774\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 774\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    777\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    778\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "File \u001b[1;32mc:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\torch\\fx\\traceback.py:57\u001b[0m, in \u001b[0;36mformat_stack\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m current_stack\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\traceback.py:197\u001b[0m, in \u001b[0;36mformat_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m--> 197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m format_list(\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\traceback.py:211\u001b[0m, in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     f \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39m_getframe()\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m--> 211\u001b[0m stack \u001b[38;5;241m=\u001b[39m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwalk_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m stack\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stack\n",
      "File \u001b[1;32mc:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\traceback.py:362\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    359\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(FrameSummary(\n\u001b[0;32m    360\u001b[0m         filename, lineno, name, lookup_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39mf_locals))\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m fnames:\n\u001b[1;32m--> 362\u001b[0m     \u001b[43mlinecache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;66;03m# If immediate lookup was desired, trigger lookups now.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookup_lines:\n",
      "File \u001b[1;32mc:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\linecache.py:72\u001b[0m, in \u001b[0;36mcheckcache\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m   \u001b[38;5;66;03m# no-op for files loaded via a __loader__\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 72\u001b[0m     stat \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     cache\u001b[38;5;241m.\u001b[39mpop(filename, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# implement the loss function\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "gamma = 0.3\n",
    "mu = np.array([0.1, 0.2])\n",
    "sigma = np.array([[0.3, 0.4], [0.1, 0.2]])\n",
    "\n",
    "# the following function is to calculate the loss of one path\n",
    "# using the continuous TD error\n",
    "def one_path_loss(new_value_net, policy, wealth_history, dt, h, gamma, mu, sigma):\n",
    "    # wealth_history: path of wealth\n",
    "    # policy: trading policy object\n",
    "    # new_value_net: new value network, the network need to be trained \n",
    "\n",
    "    n = len(wealth_history)\n",
    "    TD_error = torch.tensor(0.0, dtype = torch.float32)\n",
    "\n",
    "    # make the wealth_hisotry as 1 dimensional tensor \n",
    "    wealth_history = torch.tensor(wealth_history, dtype = torch.float32)\n",
    "\n",
    "    for i in range(2, n):\n",
    "        x = wealth_history[:i]\n",
    "        x_short = wealth_history[:i-1]\n",
    "        value_derivative = (new_value_net(x) - new_value_net(x_short)) / dt\n",
    "        entropy = policy.entropy(x, mu, sigma, dt, h, gamma)\n",
    "\n",
    "        TD_error += (value_derivative + entropy) ** 2        \n",
    "\n",
    "\n",
    "    return 0.5 * TD_error * dt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "new_value_net = SimpleLSTMModel(24)\n",
    "optimizer = torch.optim.Adam(new_value_net.parameters(), lr=0.01)\n",
    "optimizer.zero_grad()\n",
    "wealth_hisotry = torch.tensor(wealth_history, dtype = torch.float32)\n",
    "loss = one_path_loss(new_value_net, policy, wealth_history, 0.01, 0.02, 0.3, np.array([0.1, 0.2]), np.array([[0.3, 0.4], [0.1, 0.2]]))\n",
    "# move loss to GPU \n",
    "loss = loss.to(device)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "print(loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qids-2023-comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
