{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate one path for n assets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from simulation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleLSTMModel(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size=1):  # Output size is set to 1 by default\n",
    "        super(SimpleLSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        # LSTM layer expects input of shape (batch_size, seq_length, features)\n",
    "        # For a univariate sequence, features=1\n",
    "        self.lstm = nn.LSTM(1, hidden_size, batch_first=True)\n",
    "        # Fully connected layer to map the hidden state output to the desired output size\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add a batch dimension and feature dimension to x\n",
    "        # Reshaping x from (n,) to (1, n, 1) to fit LSTM input requirements\n",
    "        x = x.unsqueeze(0).unsqueeze(-1)  # Now x is of shape [1, seq_length, 1]\n",
    "        # Process x through the LSTM\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # Only use the output from the last time step\n",
    "        # This assumes you're interested in the final output for sequence processing\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        # Squeeze the output to remove 1-dimensions, aiming for a scalar output\n",
    "        return out.squeeze()\n",
    "\n",
    "# Initialize the model\n",
    "hidden_size = 10  # Number of LSTM units in the hidden layer\n",
    "\n",
    "model = SimpleLSTMModel(hidden_size)\n",
    "x = torch.randn(50)\n",
    "f = Functional(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8193344\n",
      "-0.009222329\n",
      "-0.007748604\n"
     ]
    }
   ],
   "source": [
    "dt = 0.01\n",
    "print(f.partial_t(x, dt))\n",
    "print(f.partial_x(x, dt))\n",
    "print(f.partial_xx(x, dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = generate_asset_path(mu = np.array([0.1, 0.2]), sigma = np.array([[0.3, 0.4], [0.1, 0.2]]), T = 1, dt = 0.01)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4828296572795478"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a class of trading policy \n",
    "# the trading policy object\n",
    "\n",
    "naive_states = np.array([[0.1, 0.2], [0.2, 0.3], [0.3, 0.4], [0.4, 0.5], [0.5, 0.6]])\n",
    "policy = Trading_Policy(f, naive_states)\n",
    "policy.entropy(path[0], mu = np.array([0.1, 0.2]), sigma = np.array([[0.3, 0.4], [0.1, 0.2]]), dt = 0.01, h = 0.02, gamma = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "holding_history, wealth_history = simulated_trading(policy, path, 1, np.array([0.1, 0.2]), np.array([[0.3, 0.4], [0.1, 0.2]]), 0.01, 0.1, 0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.00992246, 1.01209849, 1.00868215, 0.95768524,\n",
       "       0.95718237, 0.96225932, 0.96384248, 0.96155684, 0.9677711 ,\n",
       "       0.97340999, 0.97798528, 1.04127716, 1.02015273, 0.99079916,\n",
       "       0.99188268, 0.95329557, 0.91753839, 0.91561831, 0.95066481,\n",
       "       0.93608202, 0.94575117, 0.90857438, 0.90499673, 0.89752037,\n",
       "       0.90697818, 0.91930329, 0.94504633, 0.94009147, 0.92146011,\n",
       "       0.91492661, 0.89589574, 0.93420545, 0.955841  , 1.00505763,\n",
       "       1.03696045, 1.02823387, 0.94345624, 0.91967819, 0.88093603,\n",
       "       0.91246976, 0.91679151, 0.88983269, 0.89768684, 0.84912731,\n",
       "       0.85264281, 0.85989143, 0.87626904, 0.8782967 , 0.86830756,\n",
       "       0.89859034, 0.90871506, 0.96304566, 0.95561129, 0.94038411,\n",
       "       0.94305728, 0.94241597, 0.92219178, 0.92253946, 0.94700059,\n",
       "       0.9818742 , 0.9417577 , 0.96700662, 0.96731278, 0.98719572,\n",
       "       1.01871292, 1.00464438, 1.01448966, 1.01393933, 1.07669632,\n",
       "       1.0629594 , 1.08228684, 1.04371267, 1.11424326, 1.1170204 ,\n",
       "       1.13220506, 1.15388681, 1.11425283, 1.14066172, 1.13714629,\n",
       "       1.17658293, 1.17958478, 1.1720795 , 1.17924938, 1.19116468,\n",
       "       1.20289341, 1.1976782 , 1.19492324, 1.19778349, 1.18758613,\n",
       "       1.19870477, 1.20927948, 1.2244849 , 1.23866739, 1.21912388,\n",
       "       1.21490199, 1.23076871, 1.22451714, 1.27735347, 1.28482498])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wealth_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#optimizer = torch.optim.Adam(new_value_net.parameters(), lr=0.01)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#optimizer.zero_grad()\u001b[39;00m\n\u001b[0;32m     14\u001b[0m wealth_hisotry \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(wealth_history, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 15\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mone_path_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_value_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwealth_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.02\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#loss = loss.to(device)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#loss.backward()\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#optimizer.step()\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n",
      "File \u001b[1;32mc:\\Users\\specf\\OneDrive\\Documents\\GitHub\\Path-Dependent-Portfolio-Project\\2024_path_dependent\\simulation.py:240\u001b[0m, in \u001b[0;36mone_path_loss\u001b[1;34m(new_value_net, policy, wealth_history, dt, h, gamma, mu, sigma)\u001b[0m\n\u001b[0;32m    238\u001b[0m     x_short \u001b[38;5;241m=\u001b[39m wealth_history[:i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    239\u001b[0m     value_derivative \u001b[38;5;241m=\u001b[39m (new_value_net(x) \u001b[38;5;241m-\u001b[39m new_value_net(x_short)) \u001b[38;5;241m/\u001b[39m dt\n\u001b[1;32m--> 240\u001b[0m     entropy \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m     TD_error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (value_derivative \u001b[38;5;241m+\u001b[39m entropy) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m        \n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m TD_error \u001b[38;5;241m*\u001b[39m dt\n",
      "File \u001b[1;32mc:\\Users\\specf\\OneDrive\\Documents\\GitHub\\Path-Dependent-Portfolio-Project\\2024_path_dependent\\simulation.py:173\u001b[0m, in \u001b[0;36mTrading_Policy.entropy\u001b[1;34m(self, x, mu, sigma, dt, h, gamma)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mentropy\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mu, sigma, dt, h, gamma):\n\u001b[1;32m--> 173\u001b[0m     dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(dist \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(dist)) \u001b[38;5;241m*\u001b[39m gamma\n",
      "File \u001b[1;32mc:\\Users\\specf\\OneDrive\\Documents\\GitHub\\Path-Dependent-Portfolio-Project\\2024_path_dependent\\simulation.py:154\u001b[0m, in \u001b[0;36mTrading_Policy.distribution\u001b[1;34m(self, x, mu, sigma, dt, h, gamma)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstates)):\n\u001b[0;32m    153\u001b[0m     holdings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstates[i]\n\u001b[1;32m--> 154\u001b[0m     dist[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribution_numerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mholdings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# we have to softmax the dist, and normalize it\u001b[39;00m\n\u001b[0;32m    157\u001b[0m dist \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(dist) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mexp(dist))\n",
      "File \u001b[1;32mc:\\Users\\specf\\OneDrive\\Documents\\GitHub\\Path-Dependent-Portfolio-Project\\2024_path_dependent\\simulation.py:136\u001b[0m, in \u001b[0;36mTrading_Policy.distribution_numerator\u001b[1;34m(self, x, mu, sigma, holdings, dt, h, gamma)\u001b[0m\n\u001b[0;32m    134\u001b[0m par_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mpartial_t(x, dt)\n\u001b[0;32m    135\u001b[0m par_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mpartial_x(x, h)\n\u001b[1;32m--> 136\u001b[0m par_xx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_xx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# now, par_t, par_x, par_xx are all numpy arrays\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# mu, sigma are also numpy arrays\u001b[39;00m\n\u001b[0;32m    141\u001b[0m first_term \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmatmul(mu, holdings\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;241m*\u001b[39m par_t\n",
      "File \u001b[1;32mc:\\Users\\specf\\OneDrive\\Documents\\GitHub\\Path-Dependent-Portfolio-Project\\2024_path_dependent\\simulation.py:93\u001b[0m, in \u001b[0;36mFunctional.partial_xx\u001b[1;34m(self, x, h)\u001b[0m\n\u001b[0;32m     91\u001b[0m output_plus_h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_network(x)\n\u001b[0;32m     92\u001b[0m x[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m original_x_last \u001b[38;5;241m-\u001b[39m h\n\u001b[1;32m---> 93\u001b[0m output_minus_h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m partial_xx \u001b[38;5;241m=\u001b[39m (output_plus_h \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m output \u001b[38;5;241m+\u001b[39m output_minus_h) \u001b[38;5;241m/\u001b[39m (h \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     95\u001b[0m x[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m original_x_last  \u001b[38;5;66;03m# Reset to original last value\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[12], line 19\u001b[0m, in \u001b[0;36mSimpleLSTMModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Now x is of shape [1, seq_length, 1]\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Process x through the LSTM\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m lstm_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Only use the output from the last time step\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# This assumes you're interested in the final output for sequence processing\u001b[39;00m\n\u001b[0;32m     22\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(lstm_out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n",
      "File \u001b[1;32mc:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:774\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 774\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    777\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    778\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "File \u001b[1;32mc:\\Users\\specf\\anaconda3\\envs\\qids-2023-comp\\lib\\site-packages\\torch\\fx\\traceback.py:51\u001b[0m, in \u001b[0;36mformat_stack\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;129m@compatibility\u001b[39m(is_backward_compatible\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_stack\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_overridden:\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m current_stack\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# implement the loss function\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "gamma = 0.3\n",
    "mu = np.array([0.1, 0.2])\n",
    "sigma = np.array([[0.3, 0.4], [0.1, 0.2]])\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "new_value_net = SimpleLSTMModel(24)\n",
    "#optimizer = torch.optim.Adam(new_value_net.parameters(), lr=0.01)\n",
    "#optimizer.zero_grad()\n",
    "wealth_hisotry = torch.tensor(wealth_history, dtype = torch.float32)\n",
    "\n",
    "# only one path loss\n",
    "loss = one_path_loss(new_value_net, policy, wealth_history, 0.01, 0.02, 0.3, np.array([0.1, 0.2]), np.array([[0.3, 0.4], [0.1, 0.2]]))\n",
    "\n",
    "#loss = loss.to(device)\n",
    "#loss.backward()\n",
    "#optimizer.step()\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_f = Functional(new_value_net)\n",
    "new_policy = Trading_Policy(new_f, naive_states)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qids-2023-comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
